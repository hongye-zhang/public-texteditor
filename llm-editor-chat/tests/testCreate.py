# å®‰è£…æ‰€éœ€åº“ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
# pip install openai langchain pydantic

from pydantic import BaseModel
from typing import Optional
from langchain_openai import ChatOpenAI  # Updated import from langchain_openai
from langchain.output_parsers import PydanticOutputParser
from langchain_core.messages import SystemMessage, HumanMessage
import json
import re

# ===== 1. å®šä¹‰ç»“æ„æå–æ¨¡å‹ =====
class PPTRequest(BaseModel):
    topic: str
    use: str
    pages: int
    style: str
    structure_notes: Optional[str] = None
    words_per_page: Optional[int] = None

# ===== 2. ç”¨æˆ·è¾“å…¥ï¼ˆåŸå§‹ï¼‰=====
user_input = """æˆ‘æƒ³åšä¸€ä¸ªä»‹ç»å¤§è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²ä¸­çš„åº”ç”¨çš„PPTï¼Œç»™å†…éƒ¨äº§å“ç»„æ±‡æŠ¥ç”¨ï¼Œå¤§æ¦‚åšä¸ªäº”ã€å…­é¡µå§ï¼Œå†…å®¹å°½é‡é€šä¿—ï¼Œæ¯é¡µåˆ«å†™å¤ªå¤šï¼Œç»“æ„ä¸Šæˆ‘å¸Œæœ›æœ‰èƒŒæ™¯ã€è¶‹åŠ¿ã€åœºæ™¯ã€æœªæ¥å‡ ä¸ªæ¨¡å—ã€‚"""

# ===== 3. æå–ç»“æ„ä¿¡æ¯çš„å‡½æ•° =====
from prompts.ppt_prompts import PPTPrompts

def extract_ppt_structure(user_input, model="gpt-4o", temperature=0):
    """ä»ç”¨æˆ·è¾“å…¥ä¸­æå–PPTç»“æ„ä¿¡æ¯
    
    Args:
        user_input: ç”¨æˆ·çš„åŸå§‹è¾“å…¥æ–‡æœ¬
        model: ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹åç§°
        temperature: æ¨¡å‹ç”Ÿæˆçš„å¤šæ ·æ€§å‚æ•°
        
    Returns:
        PPTRequest: è§£æåçš„ç»“æ„æ•°æ®
    """
    # ä½¿ç”¨é™æ€æ–¹æ³•ç±»ä¸­çš„æå–ç»“æ„ä¿¡æ¯çš„ Prompt
    optimized_system_prompt = PPTPrompts.structure_extraction_prompt()

    # LangChain ç»“æ„æå–
    parser = PydanticOutputParser(pydantic_object=PPTRequest)

    # ä½¿ç”¨é™æ€æ–¹æ³•ç±»ä¸­çš„æ ¼å¼è¯´æ˜
    format_instructions = PPTPrompts.format_instructions()

    # åˆ›å»ºæ¶ˆæ¯
    system_message = SystemMessage(content=optimized_system_prompt)
    human_message = HumanMessage(content=f"{user_input}\n\nPlease output in the following format:\n{format_instructions}")

    # ä½¿ç”¨LLMè°ƒç”¨
    llm = ChatOpenAI(model=model, temperature=temperature)
    response_extract = llm.invoke([system_message, human_message])
    
    # è§£æå“åº”å†…å®¹
    return parser.parse(response_extract.content)

# è°ƒç”¨å‡½æ•°æå–ç»“æ„ä¿¡æ¯
request_data = extract_ppt_structure(user_input)

# ===== 4. ç»“æ„å¤§çº²ç”Ÿæˆ Prompt =====
# Extract JSON from potential markdown code block
def extract_json_from_markdown(text):
    # Try to find JSON content in markdown code blocks
    json_code_block_pattern = r'```(?:json)?\n(.+?)\n```'
    match = re.search(json_code_block_pattern, text, re.DOTALL)
    
    if match:
        # Return the content inside the code block
        return match.group(1)
    else:
        # If no code block found, return the original text
        return text
        
def generate_ppt_structure(request_data, model="gpt-4o", temperature=0):
    """ç”ŸæˆPPTçš„ç»“æ„å¤§çº²
    
    Args:
        request_data: ç”¨æˆ·è¯·æ±‚æ•°æ®ï¼ŒåŒ…å«ä¸»é¢˜ã€é¡µæ•°ç­‰ä¿¡æ¯
        model: ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹åç§°
        temperature: æ¨¡å‹ç”Ÿæˆçš„å¤šæ ·æ€§å‚æ•°
        
    Returns:
        dict: åŒ…å«åŸå§‹çš„sectionç»“æ„å’Œæ‰å¹³åŒ–çš„é¡µé¢åˆ—è¡¨
    """
    # ä½¿ç”¨é™æ€æ–¹æ³•ç±»ä¸­çš„ç»“æ„å¤§çº²ç”Ÿæˆ Prompt
    structure_prompt = PPTPrompts.structure_prompt(request_data)
    
    # åˆ›å»ºHumanMessageå¹¶è°ƒç”¨LLM
    structure_message = HumanMessage(content=structure_prompt)
    llm = ChatOpenAI(model=model, temperature=temperature)
    structure_response = llm.invoke([structure_message])
    
    # æå–å’Œè§£æJSONå“åº”
    json_content = extract_json_from_markdown(structure_response.content)
    section_structure = json.loads(json_content)
    
    # åˆ›å»ºä¸€ä¸ªæ‰å¹³åŒ–çš„é¡µé¢åˆ—è¡¨ï¼Œç”¨äºå…¼å®¹ç°æœ‰ä»£ç 
    flat_pages = []
    for section in section_structure:
        for page in section['pages']:
            # æ·»åŠ sectionä¿¡æ¯åˆ°é¡µé¢å¯¹è±¡
            page['section'] = section['section']
            flat_pages.append(page)
    
    # æŒ‰é¡µç æ’åº
    flat_pages.sort(key=lambda x: x['page'])
    
    # è¿”å›åŸå§‹çš„sectionç»“æ„å’Œæ‰å¹³åŒ–çš„é¡µé¢åˆ—è¡¨
    return {
        'sections': section_structure,
        'pages': flat_pages
    }

# è°ƒç”¨å‡½æ•°ç”ŸæˆPPTç»“æ„
structure_data = generate_ppt_structure(request_data)

# ===== 5. å†…å®¹ç”Ÿæˆ Promptï¼ˆç»“æ„æ™ºèƒ½åˆ¤æ–­ï¼‰=====

# å°é¢é¡µç”Ÿæˆå‡½æ•°
def generate_cover_content(page_data: dict, full_outline: dict, request_data, llm) -> str:
    """ä½¿ç”¨LLMæ ¹æ®æ•´ä¸ªPPTå¤§çº²ç”Ÿæˆå°é¢é¡µå†…å®¹
    
    Args:
        page_data: å°é¢é¡µçš„æ•°æ®
        full_outline: å®Œæ•´çš„PPTç»“æ„æ•°æ®
        request_data: ç”¨æˆ·è¯·æ±‚æ•°æ®
        llm: è¯­è¨€æ¨¡å‹å®ä¾‹
        
    Returns:
        str: ç”Ÿæˆçš„å°é¢é¡µMarkdownå†…å®¹
    """
    # é¦–å…ˆæ„å»ºå®Œæ•´å¤§çº²ä¿¡æ¯
    complete_outline = ""
    for section in full_outline['sections']:
        complete_outline += f"\nSection: {section['section']}\n"
        for page in section['pages']:
            if page['page'] > 1:  # Skip the cover page itself
                complete_outline += f"  - Page {page['page']}: {page['title']} - {page['summary']}\n"
    
    # ä½¿ç”¨é™æ€æ–¹æ³•ç±»ä¸­çš„å°é¢é¡µç”Ÿæˆ Prompt
    prompt = PPTPrompts.cover_page_prompt(request_data, complete_outline)
    
    # åˆ›å»ºHumanMessageå¹¶è°ƒç”¨LLM
    cover_message = HumanMessage(content=prompt)
    cover_response = llm.invoke([cover_message])
    
    # æå–å“åº”å†…å®¹
    cover_content = cover_response.content
    
    # å¦‚æœå“åº”åŒ…å«ä»£ç å—ï¼Œæå–å…¶ä¸­çš„å†…å®¹
    cover_content = extract_json_from_markdown(cover_content)
    
    return cover_content

# ç›®å½•é¡µè‡ªåŠ¨ç”Ÿæˆå‡½æ•°
def generate_toc_content(page_data: dict, full_outline: dict) -> str:
    """ä¸ºç›®å½•é¡µè‡ªåŠ¨ç”Ÿæˆå†…å®¹
    
    Args:
        page_data: ç›®å½•é¡µçš„æ•°æ®
        full_outline: å®Œæ•´çš„PPTç»“æ„æ•°æ®
        
    Returns:
        str: ç”Ÿæˆçš„ç›®å½•é¡µMarkdownå†…å®¹
    """
    # ç”Ÿæˆç›®å½•é¡µå†…å®¹
    toc_content = "<!-- layout: toc-list -->\n\n"
    
    # æ·»åŠ æ ‡é¢˜
    toc_content += f"# {page_data['title']}\n\n"
    
    # ä¸ºæ¯ä¸ªåˆ†åŒºç”Ÿæˆç›®å½•é¡¹
    for section in full_outline['sections']:
        section_name = section['section']
        toc_content += f"## {section_name}\n\n"
        
        # æ·»åŠ è¯¥åˆ†åŒºçš„é¡µé¢ï¼ˆè·³è¿‡å°é¢å’Œç›®å½•é¡µæœ¬èº«ï¼‰
        for page in section['pages']:
            if page['page'] <= 2:  # è·³è¿‡å°é¢å’Œç›®å½•é¡µ
                continue
            toc_content += f"- {page['title']} ... {page['page']}\n"
        
        toc_content += "\n"
    
    return toc_content

# æ£€æŸ¥é¡µé¢æ˜¯å¦ä¸ºå°é¢é¡µ
def is_cover_page(page_data: dict) -> bool:
    """æ£€æŸ¥é¡µé¢æ˜¯å¦ä¸ºå°é¢é¡µ
    
    Args:
        page_data: é¡µé¢æ•°æ®
        
    Returns:
        bool: æ˜¯å¦ä¸ºå°é¢é¡µ
    """
    # æ£€æŸ¥é¡µç ï¼ˆé€šå¸¸å°é¢é¡µæ˜¯ç¬¬1é¡µï¼‰
    if page_data['page'] == 1:
        return True
    
    # æ£€æŸ¥æ ‡é¢˜å…³é”®è¯
    title_lower = page_data['title'].lower()
    cover_keywords = ['cover', 'å°é¢', 'title', 'æ ‡é¢˜', 'front']
    for keyword in cover_keywords:
        if keyword in title_lower:
            return True
    
    return False

# æ£€æŸ¥é¡µé¢æ˜¯å¦ä¸ºç›®å½•é¡µ
def is_toc_page(page_data: dict) -> bool:
    """æ£€æŸ¥é¡µé¢æ˜¯å¦ä¸ºç›®å½•é¡µ
    
    Args:
        page_data: é¡µé¢æ•°æ®
        
    Returns:
        bool: æ˜¯å¦ä¸ºç›®å½•é¡µ
    """
    # æ£€æŸ¥é¡µç ï¼ˆé€šå¸¸ç›®å½•é¡µæ˜¯ç¬¬2é¡µï¼‰
    if page_data['page'] == 2:
        return True
    
    # æ£€æŸ¥æ ‡é¢˜å…³é”®è¯
    title_lower = page_data['title'].lower()
    toc_keywords = ['content', 'ç›®å½•', 'agenda', 'outline', 'table of contents']
    for keyword in toc_keywords:
        if keyword in title_lower:
            return True
    
    return False

# å†…å®¹ç”Ÿæˆå‡½æ•°
def content_prompt_markdown_structured(summary_text: str, topic: str, page_num: int, section_name: str, style: str, full_outline: dict, words_per_page: int = 120) -> str:
    
    # è·å–å½“å‰é¡µé¢æ‰€å±çš„sectionä¸­çš„æ‰€æœ‰é¡µé¢
    current_section_pages = []
    for section in full_outline['sections']:
        if section['section'] == section_name:
            current_section_pages = section['pages']
            break
    
    # æ„å»ºå½“å‰åˆ†åŒºçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    section_context = f"\n\nCurrent Section: {section_name}\n"
    for page in current_section_pages:
        if page['page'] < page_num:  # åªåŒ…å«å½“å‰é¡µé¢ä¹‹å‰çš„é¡µé¢
            section_context += f"- Page {page['page']}: {page['title']} - {page['summary']}\n"
    
    # æ„å»ºå®Œæ•´å¤§çº²çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    outline_context = "\n\nFull PPT Outline (by sections):\n"
    for section in full_outline['sections']:
        outline_context += f"Section: {section['section']}\n"
        for page in section['pages']:
            outline_context += f"  - Page {page['page']}: {page['title']}\n"
    
    # ä½¿ç”¨é™æ€æ–¹æ³•ç±»ä¸­çš„å†…å®¹ç”Ÿæˆ Prompt
    return PPTPrompts.content_generation_prompt(
        summary_text=summary_text,
        topic=topic,
        page_num=page_num,
        section_name=section_name,
        style=style,
        section_context=section_context,
        outline_context=outline_context,
        words_per_page=words_per_page
    )

# é¡µé¢å†…å®¹ç”Ÿæˆå‡½æ•°
def generate_page_content(page_data, structure_data, request_data, llm, verbose=True):
    """æ ¹æ®é¡µé¢ç±»å‹ç”Ÿæˆç›¸åº”çš„å†…å®¹
    
    Args:
        page_data: é¡µé¢æ•°æ®
        structure_data: å®Œæ•´çš„PPTç»“æ„æ•°æ®
        request_data: ç”¨æˆ·è¯·æ±‚æ•°æ®
        llm: è¯­è¨€æ¨¡å‹å®ä¾‹
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
    Returns:
        str: ç”Ÿæˆçš„é¡µé¢å†…å®¹
    """
    # æ£€æŸ¥é¡µé¢ç±»å‹å¹¶åˆ†åˆ«å¤„ç†
    if is_cover_page(page_data):
        # å¦‚æœæ˜¯å°é¢é¡µï¼Œä½¿ç”¨ç‰¹æ®Šå¤„ç†
        if verbose:
            print(f"\nğŸ“– æ£€æµ‹åˆ°å°é¢é¡µ: {page_data['title']} (ç¬¬{page_data['page']}é¡µ)")
            print("\nğŸ“ åŸºäºå®Œæ•´å¤§çº²ç”Ÿæˆå°é¢å†…å®¹\n")
        
        # ä½¿ç”¨LLMç”Ÿæˆå°é¢å†…å®¹ï¼ŒåŸºäºæ•´ä¸ªPPTå¤§çº²
        content_result = generate_cover_content(page_data, structure_data, request_data, llm)
        
    elif is_toc_page(page_data):
        # å¦‚æœæ˜¯ç›®å½•é¡µï¼Œä½¿ç”¨ç‰¹æ®Šå¤„ç†
        if verbose:
            print(f"\nğŸ“— æ£€æµ‹åˆ°ç›®å½•é¡µ: {page_data['title']} (ç¬¬{page_data['page']}é¡µ)")
            print("\nğŸ“ è‡ªåŠ¨ç”Ÿæˆç›®å½•å†…å®¹\n")
        
        # è·³è¿‡LLMè°ƒç”¨ï¼Œç›´æ¥ä½¿ç”¨ç”Ÿæˆçš„ç›®å½•å†…å®¹
        content_result = generate_toc_content(page_data, structure_data)
        
    else:
        # å¦‚æœæ˜¯æ™®é€šå†…å®¹é¡µï¼Œä½¿ç”¨æ­£å¸¸çš„å†…å®¹ç”Ÿæˆæµç¨‹
        if verbose:
            print(f"\nğŸ“˜ å¤„ç†æ™®é€šå†…å®¹é¡µ: {page_data['title']} (ç¬¬{page_data['page']}é¡µ)")
        
        # ç”Ÿæˆå†…å®¹æç¤º
        content_prompt = content_prompt_markdown_structured(
            summary_text=page_data["summary"],
            topic=page_data["title"],
            page_num=page_data["page"],
            section_name=page_data["section"],  # æ·»åŠ sectionä¿¡æ¯
            style=request_data.style,
            full_outline=structure_data,  # ä¼ å…¥å®Œæ•´ç»“æ„æ•°æ®
            words_per_page=request_data.words_per_page or 120
        )

        # åˆ›å»ºHumanMessageå¹¶è°ƒç”¨LLM
        content_message = HumanMessage(content=content_prompt)
        content_response = llm.invoke([content_message])

        # æ¸…ç†å“åº”å†…å®¹ï¼Œå¤„ç†å¯èƒ½çš„markdownä»£ç å—
        content_result = extract_json_from_markdown(content_response.content)
    
    return content_result

# ===== 6. å†…å®¹ç”Ÿæˆè°ƒç”¨ï¼ˆç¤ºä¾‹ï¼‰=====
# é€‰æ‹©è¦ç”Ÿæˆå†…å®¹çš„é¡µé¢ï¼ˆè¿™é‡Œé€‰æ‹©ç¬¬ä¸€é¡µï¼Œå°é¢é¡µï¼‰
selected_page_index = 0  # ç´¢å¼•ä»0å¼€å§‹ï¼Œæ‰€ä»¥è¿™æ˜¯ç¬¬1é¡µ
selected_page = structure_data['pages'][selected_page_index]

# è°ƒç”¨å‡½æ•°ç”Ÿæˆé¡µé¢å†…å®¹
content_result = generate_page_content(selected_page, structure_data, request_data, llm)

# å¦‚æœæƒ³æµ‹è¯•å…¶ä»–é¡µé¢ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¹¶é€‰æ‹©ä¸åŒé¡µé¢
# selected_page_index = 1  # é€‰æ‹©ç¬¬2é¡µï¼ˆç›®å½•é¡µï¼‰
# selected_page = structure_data['pages'][selected_page_index]
# content_result = generate_page_content(selected_page, structure_data, request_data, llm)

# selected_page_index = 2  # é€‰æ‹©ç¬¬3é¡µï¼ˆå†…å®¹é¡µï¼‰
# selected_page = structure_data['pages'][selected_page_index]
# content_result = generate_page_content(selected_page, structure_data, request_data, llm)

# ===== 7. æ‰“å°è¾“å‡ºç»“æ„ä¸å†…å®¹ =====
# æ‰“å°é€‰å®šé¡µé¢çš„ä¿¡æ¯
print(f"ğŸ“˜ ç»“æ„å¤§çº²ï¼ˆç¬¬{selected_page['page']}é¡µï¼Œå±äº '{selected_page['section']}' åˆ†åŒºï¼‰ï¼š\n", 
      json.dumps(selected_page, ensure_ascii=False, indent=2))

# æ‰“å°å®Œæ•´çš„åˆ†åŒºç»“æ„ï¼ˆå¯é€‰ï¼‰
print("\nğŸ“— å®Œæ•´PPTç»“æ„ï¼ˆåˆ†åŒºæ•°ï¼‰ï¼š", len(structure_data['sections']))
for i, section in enumerate(structure_data['sections']):
    print(f"  - åˆ†åŒº {i+1}: {section['section']} (åŒ…å«{len(section['pages'])}é¡µ)")

# æ‰“å°ç”Ÿæˆçš„å†…å®¹
print("\nğŸ“ å†…å®¹è¾“å‡ºï¼ˆç»“æ„åŒ– Markdownï¼‰ï¼š\n", content_result)
